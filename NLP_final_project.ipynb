{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-lingual sentiment analysis on the Bible\n",
        "## 1. Loading the datasets"
      ],
      "metadata": {
        "id": "DZ_UPtR7TY4l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3B72hwmTOFK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "bible = pd.read_csv(r'/content/drive/MyDrive/kjv.csv')\n",
        "bible_sp = pd.read_csv(r'/content/drive/MyDrive/rv_1909_sp.csv')\n",
        "bible_de = pd.read_csv(r'/content/drive/MyDrive/elberfelder_1905_de.csv')\n",
        "bible_it = pd.read_csv(r'/content/drive/MyDrive/diodati_it.csv')\n",
        "bible_fr = pd.read_csv(r'/content/drive/MyDrive/oster_fr.csv')\n",
        "bible_nl = pd.read_csv(r'/content/drive/MyDrive/stve_dutch.csv')\n",
        "ab = pd.read_csv(r'/content/drive/MyDrive/svd.csv')\n",
        "id = pd.read_csv(r'/content/drive/MyDrive/indo_tb.csv')\n",
        "ps = pd.read_csv(r'/content/drive/MyDrive/opt.csv')\n",
        "tk = pd.read_csv(r'/content/drive/MyDrive/turkish.csv')\n",
        "jp = pd.read_csv(r'/content/drive/MyDrive/kougo.csv')\n"
      ],
      "metadata": {
        "id": "cOrsCbnMTWA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loading models and running sentiment analysis"
      ],
      "metadata": {
        "id": "VXB9UPn8ToU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### English dataset"
      ],
      "metadata": {
        "id": "Cy_FTdAEnkSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = bible['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "bible['Sentiment'] = [result['label'] for result in sentiments]\n",
        "bible['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=bible)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "bible.to_csv('bible_sent_3.csv')\n",
        "!cp bible_sent_3.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "xCBJ0ICeUXsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dutch dataset"
      ],
      "metadata": {
        "id": "WLLxcGtBo1Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = bible_nl['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "bible_nl['Sentiment'] = [result['label'] for result in sentiments]\n",
        "bible_nl['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=bible_nl)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "bible_nl.to_csv('bible_nl_sent.csv')\n",
        "!cp bible_nl_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "mCwByLbyo4Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### French dataset"
      ],
      "metadata": {
        "id": "ZkUJzuU2o6hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = bible_fr['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "bible_fr['Sentiment'] = [result['label'] for result in sentiments]\n",
        "bible_fr['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=bible_fr)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "bible_fr.to_csv('bible_fr_sent.csv')\n",
        "!cp bible_fr_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "EKVk31m9pB18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### German dataset"
      ],
      "metadata": {
        "id": "wZkwobCjo8eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = bible_de['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "bible_de['Sentiment'] = [result['label'] for result in sentiments]\n",
        "bible_de['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=bible_de)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "bible_de.to_csv('bible_de_sent.csv')\n",
        "!cp bible_de_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "pecyYy4UpCpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Italian dataset"
      ],
      "metadata": {
        "id": "mQaoumq4o99i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = bible_it['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "bible_it['Sentiment'] = [result['label'] for result in sentiments]\n",
        "bible_it['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=bible_it)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "bible_it.to_csv('bible_it_sent.csv')\n",
        "!cp bible_it_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "9wcppmwHpDNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spanish dataset"
      ],
      "metadata": {
        "id": "3z611k1Uo_pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = bible_sp['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "bible_sp['Sentiment'] = [result['label'] for result in sentiments]\n",
        "bible_sp['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=bible_sp)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "bible_sp.to_csv('bible_sp_sent.csv')\n",
        "!cp bible_sp_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "bnIR_mxgpDzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arabic dataset"
      ],
      "metadata": {
        "id": "BvZPWjSVqgSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = ab['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "ab['Sentiment'] = [result['label'] for result in sentiments]\n",
        "ab['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=ab)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "ab.to_csv('ab_sent.csv')\n",
        "!cp ab_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "yJlVt6K-sSQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indonesian dataset"
      ],
      "metadata": {
        "id": "eqM7QRbisGZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = id['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "id['Sentiment'] = [result['label'] for result in sentiments]\n",
        "id['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=id)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "id.to_csv('id_sent.csv')\n",
        "!cp id_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "25sVHkb_sStq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Japanese dataset"
      ],
      "metadata": {
        "id": "BCBwtmRHsNak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = jp['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"christian-phu/bert-finetuned-japanese-sentiment\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "jp['Sentiment'] = [result['label'] for result in sentiments]\n",
        "jp['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=jp)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "jp.to_csv('jp_sent.csv')\n",
        "!cp jp_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "7S1st42msTGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persian dataset"
      ],
      "metadata": {
        "id": "X_XKjc_FsPxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = ps['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "ps['Sentiment'] = [result['label'] for result in sentiments]\n",
        "ps['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=ps)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "ps.to_csv('ps_sent.csv')\n",
        "!cp ps_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "-6r4CYu9sTdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turkish dataset"
      ],
      "metadata": {
        "id": "EFgJ1C9XsQ2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all text data into a single list to run on sentiment analysis model\n",
        "texts = tk['Text'].tolist()\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"savasy/bert-base-turkish-sentiment-cased\")\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Addding results to bible dataframe\n",
        "tk['Sentiment'] = [result['label'] for result in sentiments]\n",
        "tk['Sentiment_Score'] = [result['score'] for result in sentiments]\n",
        "\n",
        "# Create sentiment distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Sentiment', data=tk)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()\n",
        "\n",
        "# Save off model\n",
        "tk.to_csv('tk_sent.csv')\n",
        "!cp tk_sent.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "FBL9hYw1sUXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Analyzing model performance"
      ],
      "metadata": {
        "id": "oROdhMjfTrYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multilingual model"
      ],
      "metadata": {
        "id": "bjfQcS3pujAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = [en.assign(Translation='English'),\n",
        "       sp.assign(Translation='Spanish'),\n",
        "       fr.assign(Translation='French'),\n",
        "       nl.assign(Translation='Dutch'),\n",
        "       de.assign(Translation='German'),\n",
        "       it.assign(Translation='Italian')]\n",
        "df_all = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "Gjjuymfwuq8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star_mapping = {'5 stars': 5, '4 stars': 4, '3 stars': 3, '2 stars': 2, '1 star': 1}\n",
        "df_all['Star_Num'] = df_all['Sentiment'].map(star_mapping)\n",
        "\n",
        "# Calculate the total stars and total verses for each book and translation\n",
        "book_stats = df_all.groupby(['Translation', 'Book Name', 'Book Number']).agg({'Star_Num': 'sum', 'Verse ID': 'count'})\n",
        "\n",
        "# Calculate the average sentiment score for each book and translation\n",
        "book_stats['Average_Sentiment'] = book_stats['Star_Num'] / (book_stats['Verse ID'])\n",
        "book_stats = book_stats.reset_index()"
      ],
      "metadata": {
        "id": "bLnfwCdLvmbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of sentiments\n",
        "plt.hist(df_all['Star_Num'], bins=[1, 2, 3, 4, 5, 6], align='left', rwidth=0.8)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Star Number')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Star Numbers')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Average sentiment per language\n",
        "translation_stats = book_stats.groupby('Translation').agg({'Average_Sentiment': 'mean'})\n",
        "\n",
        "# Display the results\n",
        "print(\"Average Sentiment Scores for Each Translation:\")\n",
        "print(translation_stats[['Average_Sentiment']])"
      ],
      "metadata": {
        "id": "Kj43_e3KvVyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average scores per book of each language\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create subplots for each translation\n",
        "translations = book_stats['Translation'].unique()\n",
        "num_translations = len(translations)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=num_translations, figsize=(10, 5*num_translations), sharex=True)\n",
        "\n",
        "for i, translation in enumerate(translations):\n",
        "  ax = axes[i]\n",
        "  translation_data = book_stats[book_stats['Translation'] == translation]\n",
        "\n",
        "  # Create a bar plot for average sentiment per book within each translation\n",
        "  sns.barplot(x='Book Number', y='Average_Sentiment', data=translation_data, ax=ax)\n",
        "\n",
        "  ax.set_title(f'Average Sentiment per Book - {translation}')\n",
        "  ax.set_xlabel('Book Number')\n",
        "  ax.set_ylabel('Average Sentiment')\n",
        "  ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "\n",
        "# Adjust layout and show plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EGfryMHhvw8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='Book Number', y='Average_Sentiment', data=book_stats)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jwWdJDM7zSat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall accuracy and distribution of accuracies\n",
        "accuracy = df_all['Sentiment_Score'].mean()\n",
        "print(\"Overall accuracy: \", accuracy)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df_all['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P_UAyuUT0bhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arabic"
      ],
      "metadata": {
        "id": "uz1clU0PukmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by book to compute average sentiment per book\n",
        "average_sentiment_by_book = ab.groupby('Book Number')['Sentiment'].apply(lambda x: (x == 'HAPPY').sum() / len(x) * 100)\n",
        "\n",
        "# Display the results in order by book number (rather than book name)\n",
        "result_df = pd.DataFrame({\n",
        "  'Book Number': average_sentiment_by_book.index,\n",
        "  'Average Sentiment (%)': average_sentiment_by_book.values\n",
        "})\n",
        "\n",
        "result_df = result_df.sort_values(by='Book Number')\n",
        "\n",
        "# Plot bar graph of the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(result_df['Book Number'], result_df['Average Sentiment (%)'], color='skyblue')\n",
        "plt.xlabel('Book Number')\n",
        "plt.ylabel('Average Sentiment (%)')\n",
        "plt.title('Average Sentiment for Each Book')\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D7KpO1W2162v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of accuracy (sentiment score)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(ab['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Overall accuracy\n",
        "accuracy = ab['Sentiment_Score'].mean()\n",
        "print(\"Overall accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "-maZ2hU48756"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indonesian"
      ],
      "metadata": {
        "id": "N6eSdQVkulzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by book to compute average sentiment per book\n",
        "average_sentiment_by_book = id.groupby('Book Number')['Sentiment'].apply(lambda x: (x == 'HAPPY').sum() / len(x) * 100)\n",
        "\n",
        "# Display the results in order by book number (rather than book name)\n",
        "result_df = pd.DataFrame({\n",
        "  'Book Number': average_sentiment_by_book.index,\n",
        "  'Average Sentiment (%)': average_sentiment_by_book.values\n",
        "})\n",
        "\n",
        "result_df = result_df.sort_values(by='Book Number')\n",
        "\n",
        "# Plot bar graph of the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(result_df['Book Number'], result_df['Average Sentiment (%)'], color='skyblue')\n",
        "plt.xlabel('Book Number')\n",
        "plt.ylabel('Average Sentiment (%)')\n",
        "plt.title('Average Sentiment for Each Book')\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FUVKOLna82xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of accuracy (sentiment score)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(id['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Overall accuracy\n",
        "accuracy = id['Sentiment_Score'].mean()\n",
        "print(\"Overall accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "yt-UfDn6jh0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Japanese"
      ],
      "metadata": {
        "id": "59CNKYpXunM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by book to compute average sentiment per book\n",
        "average_sentiment_by_book = jp.groupby('Book Number')['Sentiment'].apply(lambda x: (x == 'HAPPY').sum() / len(x) * 100)\n",
        "\n",
        "# Display the results in order by book number (rather than book name)\n",
        "result_df = pd.DataFrame({\n",
        "  'Book Number': average_sentiment_by_book.index,\n",
        "  'Average Sentiment (%)': average_sentiment_by_book.values\n",
        "})\n",
        "\n",
        "result_df = result_df.sort_values(by='Book Number')\n",
        "\n",
        "# Plot bar graph of the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(result_df['Book Number'], result_df['Average Sentiment (%)'], color='skyblue')\n",
        "plt.xlabel('Book Number')\n",
        "plt.ylabel('Average Sentiment (%)')\n",
        "plt.title('Average Sentiment for Each Book')\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MhQF8H2XjhGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of accuracy (sentiment score)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(jp['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Overall accuracy\n",
        "accuracy = jp['Sentiment_Score'].mean()\n",
        "print(\"Overall accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "KfOz6wHkjff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persian"
      ],
      "metadata": {
        "id": "n3RpC6j4uoL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by book to compute average sentiment per book\n",
        "average_sentiment_by_book = ps.groupby('Book Number')['Sentiment'].apply(lambda x: (x == 'HAPPY').sum() / len(x) * 100)\n",
        "\n",
        "# Display the results in order by book number (rather than book name)\n",
        "result_df = pd.DataFrame({\n",
        "  'Book Number': average_sentiment_by_book.index,\n",
        "  'Average Sentiment (%)': average_sentiment_by_book.values\n",
        "})\n",
        "\n",
        "result_df = result_df.sort_values(by='Book Number')\n",
        "\n",
        "# Plot bar graph of the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(result_df['Book Number'], result_df['Average Sentiment (%)'], color='skyblue')\n",
        "plt.xlabel('Book Number')\n",
        "plt.ylabel('Average Sentiment (%)')\n",
        "plt.title('Average Sentiment for Each Book')\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZIdpVXDcjgyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of accuracy (sentiment score)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(ps['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Overall accuracy\n",
        "accuracy = ps['Sentiment_Score'].mean()\n",
        "print(\"Overall accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "uJIyyRiajf2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turkish"
      ],
      "metadata": {
        "id": "oyFmH9Ddupte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by book to compute average sentiment per book\n",
        "average_sentiment_by_book = tk.groupby('Book Number')['Sentiment'].apply(lambda x: (x == 'HAPPY').sum() / len(x) * 100)\n",
        "\n",
        "# Display the results in order by book number (rather than book name)\n",
        "result_df = pd.DataFrame({\n",
        "  'Book Number': average_sentiment_by_book.index,\n",
        "  'Average Sentiment (%)': average_sentiment_by_book.values\n",
        "})\n",
        "\n",
        "result_df = result_df.sort_values(by='Book Number')\n",
        "\n",
        "# Plot bar graph of the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(result_df['Book Number'], result_df['Average Sentiment (%)'], color='skyblue')\n",
        "plt.xlabel('Book Number')\n",
        "plt.ylabel('Average Sentiment (%)')\n",
        "plt.title('Average Sentiment for Each Book')\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D1fiX1TJjghq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of accuracy (sentiment score)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(tk['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Overall accuracy\n",
        "accuracy = tk['Sentiment_Score'].mean()\n",
        "print(\"Overall accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "kWr2c2ZFjgTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Comparing results across languages"
      ],
      "metadata": {
        "id": "gZxhGsbBTubQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing accuracy and distribution of sentiment scores"
      ],
      "metadata": {
        "id": "77DEI7h9AQrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall sentiment and score distribution\n",
        "\n",
        "# Combining results into one large dataframe\n",
        "dfs = [en.assign(Translation='English'),\n",
        "       sp.assign(Translation='Spanish'),\n",
        "       fr.assign(Translation='French'),\n",
        "       nl.assign(Translation='Dutch'),\n",
        "       de.assign(Translation='German'),\n",
        "       it.assign(Translation='Italian'),\n",
        "       ab.assign(Translation='Arabic'),\n",
        "       id.assign(Translation='Indonesian'),\n",
        "       ps.assign(Translation='Persian'),\n",
        "       tk.assign(Translation='Turkish'),\n",
        "       jp.assign(Translation='Japanese'),\n",
        "       ]\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Plot histogram of accuracies\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df_all['Sentiment_Score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prLoyOpt2Ebz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map sentiment values to a 5 point scale, with positive mapping to 5,\n",
        "# negative to 1, and neutral to 3\n",
        "sentiment_mapping = {\n",
        "    '1 star': 1,\n",
        "    '2 stars': 2,\n",
        "    '3 stars': 3,\n",
        "    '4 stars': 4,\n",
        "    '5 stars': 5,\n",
        "    'positive': 5,\n",
        "    'negative': 1,\n",
        "    'Positive': 5,\n",
        "    'Negative': 1,\n",
        "    'neutral': 3,\n",
        "    'Neutral': 3,\n",
        "    'HAPPY': 5,\n",
        "    'SAD': 1\n",
        "}\n",
        "\n",
        "df_all['Mapped_Sentiment'] = df_all['Sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# Plot distribution of sentiments across all translations\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Mapped_Sentiment', data=df_all)\n",
        "plt.title('Distribution of Sentiments in the Bible Text')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yLIl9h_q05t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average sentiment by language\n",
        "\n",
        "# Create book_stats dataframe to calculate book-level data\n",
        "# (i.e. averages per each book within all translations)\n",
        "book_stats = df_all.groupby(['Translation', 'Book Name', 'Book Number']).agg({'Mapped_Sentiment': 'sum', 'Verse ID': 'count'})\n",
        "\n",
        "# Calculate the average sentiment for each book and translation\n",
        "book_stats['Average_Sentiment'] = book_stats['Mapped_Sentiment'] / (book_stats['Verse ID'])\n",
        "book_stats = book_stats.reset_index()\n",
        "\n",
        "translation_stats = book_stats.groupby('Translation').agg({'Average_Sentiment': 'mean'})\n",
        "\n",
        "print(\"Average Sentiment Scores for Each Translation:\")\n",
        "print(translation_stats[['Average_Sentiment']])"
      ],
      "metadata": {
        "id": "Kf_jig3q1dfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute overall accuracy of all models by utilizing Sentiment_Score\n",
        "\n",
        "print(\"Overall:    \", df_all['Sentiment_Score'].mean())\n",
        "print(\"Arabic:     \", ab['Sentiment_Score'].mean())\n",
        "print(\"Indonesian: \", id['Sentiment_Score'].mean())\n",
        "print(\"Persian:    \", ps['Sentiment_Score'].mean())\n",
        "print(\"Turkish:    \", tk['Sentiment_Score'].mean())\n",
        "print(\"Japanese:   \", jp['Sentiment_Score'].mean())\n",
        "print(\"Dutch:      \", nl['Sentiment_Score'].mean())\n",
        "print(\"English:    \", en['Sentiment_Score'].mean())\n",
        "print(\"German:     \", de['Sentiment_Score'].mean())\n",
        "print(\"Spanish:    \", sp['Sentiment_Score'].mean())\n",
        "print(\"Italian:    \", it['Sentiment_Score'].mean())\n",
        "print(\"French:     \", fr['Sentiment_Score'].mean())"
      ],
      "metadata": {
        "id": "C2-YrID5ara8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing results per book across languages"
      ],
      "metadata": {
        "id": "VdAPKOBEAhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average sentiment by book across all translations\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=book_stats.groupby('Book Number')['Average_Sentiment'].mean().reset_index(),\n",
        "            x='Book Number', y='Average_Sentiment', color='skyblue')\n",
        "plt.title('Average Sentiment of Each Book Across Translations')\n",
        "plt.xlabel('Book Number')\n",
        "plt.ylabel('Average Sentiment Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m4DZ0Mlv9acv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average sentiment by section of the bible\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 1) & (book_stats['Book Number'] <= 5)]\n",
        "average_sentiment_torah = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Torah: {average_sentiment_torah}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 6) & (book_stats['Book Number'] <= 17)]\n",
        "average_sentiment_historical = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Historical: {average_sentiment_historical}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 18) & (book_stats['Book Number'] <= 22)]\n",
        "average_sentiment_poetic = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Poetic: {average_sentiment_poetic}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 23) & (book_stats['Book Number'] <= 39)]\n",
        "average_sentiment_prophetic = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Prophetic: {average_sentiment_prophetic}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 40) & (book_stats['Book Number'] <= 43)]\n",
        "average_sentiment_gospels = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Gospels: {average_sentiment_gospels}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 44) & (book_stats['Book Number'] <= 44)]\n",
        "average_sentiment_acts = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Acts: {average_sentiment_acts}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 45) & (book_stats['Book Number'] <= 65)]\n",
        "average_sentiment_letters = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Letters: {average_sentiment_letters}\")\n",
        "\n",
        "filtered_books = book_stats[(book_stats['Book Number'] >= 66) & (book_stats['Book Number'] <= 66)]\n",
        "average_sentiment_revelation = filtered_books['Average_Sentiment'].mean()\n",
        "print(f\"Average Sentiment for Revelation: {average_sentiment_revelation}\")\n",
        "\n",
        "book_level = [['Torah', average_sentiment_torah], ['Historical', average_sentiment_historical], ['Poetic', average_sentiment_poetic], ['Prophetic', average_sentiment_prophetic], ['Gospels', average_sentiment_gospels], ['Acts', average_sentiment_acts], ['Letters', average_sentiment_letters], ['Revelation', average_sentiment_revelation], ]\n",
        "\n",
        "eras = pd.DataFrame(book_level, columns=['Section', 'Average Sentiment'])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(eras['Section'], eras['Average Sentiment'], color='skyblue')\n",
        "plt.title('Average Sentiment for Each Section')\n",
        "plt.xlabel('Section')\n",
        "plt.ylabel('Average Sentiment')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nKE_fjIOGi3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot of standard deviation\n",
        "plt.rcParams['figure.figsize'] = [15, 5]\n",
        "sns.boxplot(x='Book Number', y='Average_Sentiment', data=book_stats)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WyOTfwO92JO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing results at the word-level across languages"
      ],
      "metadata": {
        "id": "ddUY_rnoAmLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing words across translations\n",
        "# Downloading tokenizers\n",
        "import ast\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "spacy.cli.download(\"es_core_news_sm\")\n",
        "spacy.cli.download(\"it_core_news_sm\")\n",
        "spacy.cli.download(\"pt_core_news_sm\")\n",
        "spacy.cli.download(\"de_core_news_sm\")\n",
        "spacy.cli.download(\"nl_core_news_sm\")\n",
        "spacy.cli.download(\"fr_core_news_sm\")\n",
        "spacy.cli.download(\"ja_core_news_sm\")\n",
        "\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "nlp_it = spacy.load(\"it_core_news_sm\")\n",
        "nlp_pt = spacy.load(\"pt_core_news_sm\")\n",
        "nlp_de = spacy.load(\"de_core_news_sm\")\n",
        "nlp_nl = spacy.load(\"nl_core_news_sm\")\n",
        "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
        "nlp_ja = spacy.load(\"ja_core_news_sm\")\n",
        "\n",
        "tokenizer_arabic = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "tokenizer_indonesian = AutoTokenizer.from_pretrained(\"cahya/bert-base-indonesian-522M\")\n",
        "tokenizer_turkish = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
        "tokenizer_persian = AutoTokenizer.from_pretrained(\"bolbolzaban/gpt2-persian\")\n",
        "\n",
        "\n",
        "# Preprocess text by removing stopwords for languages with pre-existing libraries,\n",
        "# which does not include any of the non-European languages except Japanese\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text_en(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words_en]\n",
        "  return tokens\n",
        "\n",
        "def preprocess_text_spacy(text, lang):\n",
        "  if lang == 'Spanish':\n",
        "      tokens = [token.text.lower() for token in nlp_es(text) if token.text.isalnum() and token.text.lower() not in nlp_es.Defaults.stop_words]\n",
        "  elif lang == 'Italian':\n",
        "      tokens = [token.text.lower() for token in nlp_it(text) if token.text.isalnum() and token.text.lower() not in nlp_it.Defaults.stop_words]\n",
        "  elif lang == 'German':\n",
        "      tokens = [token.text.lower() for token in nlp_de(text) if token.text.isalnum() and token.text.lower() not in nlp_de.Defaults.stop_words]\n",
        "  elif lang == 'Dutch':\n",
        "      tokens = [token.text.lower() for token in nlp_nl(text) if token.text.isalnum() and token.text.lower() not in nlp_nl.Defaults.stop_words]\n",
        "  elif lang == 'French':\n",
        "      tokens = [token.text.lower() for token in nlp_fr(text) if token.text.isalnum() and token.text.lower() not in nlp_fr.Defaults.stop_words]\n",
        "  elif lang == 'Japanese':\n",
        "      tokens = [token.text.lower() for token in nlp_ja(text) if token.text.isalnum() and token.text.lower() not in nlp_ja.Defaults.stop_words]\n",
        "  elif lang == 'Arabic':\n",
        "      tokens = tokenizer_arabic.tokenize(tokenizer_arabic.decode(tokenizer_arabic.encode(text)))\n",
        "  elif lang == 'Indonesian':\n",
        "      tokens = tokenizer_indonesian.tokenize(tokenizer_indonesian.decode(tokenizer_indonesian.encode(text)))\n",
        "  elif lang == 'Turkish':\n",
        "      tokens = tokenizer_turkish.tokenize(tokenizer_turkish.decode(tokenizer_turkish.encode(text)))\n",
        "  elif lang == 'Persian':\n",
        "      tokens = tokenizer_persian.tokenize(tokenizer_persian.decode(tokenizer_persian.encode(text)))\n",
        "  else:\n",
        "      tokens = []\n",
        "  return tokens\n",
        "\n",
        "df_all['Processed_Text_En'] = df_all[df_all['Translation'] == 'English']['Text'].apply(preprocess_text_en)\n",
        "df_all['Processed_Text_Spacy'] = df_all[df_all['Translation'] != 'English'].apply(lambda row: preprocess_text_spacy(row['Text'], row['Translation']), axis=1)\n",
        "\n",
        "\n",
        "# Combine processed text columns and add to the df_all dataframe\n",
        "df_all['Combined_Processed_Text'] = df_all['Processed_Text_En'].combine_first(df_all['Processed_Text_Spacy'])\n",
        "\n",
        "# Save off results\n",
        "df_all.to_csv('bible_all_langs_stopwords.csv')\n",
        "!cp bible_all_langs_stopwords.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "lSWCr1yYG3Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gathering the top 75 words in high sentiment and in low sentiment verses\n",
        "\n",
        "high_sentiment_data = df_all[df_all['Mapped_Sentiment'] == 5]\n",
        "low_sentiment_data = df_all[df_all['Mapped_Sentiment'] == 1]\n",
        "\n",
        "# Count word frequencies for high sentiment verses and low sentiment verses\n",
        "high_sentiment_word_counts = high_sentiment_data.groupby(['Translation'])['Combined_Processed_Text'].apply(lambda x: pd.Series(' '.join(x).split())).reset_index()\n",
        "low_sentiment_word_counts = low_sentiment_data.groupby(['Translation'])['Combined_Processed_Text'].apply(lambda x: pd.Series(' '.join(x).split())).reset_index()\n",
        "\n",
        "# Identify 75 most common high and low sentiment words by language\n",
        "common_high_sentiment_words = {}\n",
        "for lang in high_sentiment_word_counts['Translation'].unique():\n",
        "  words_freq = high_sentiment_word_counts[high_sentiment_word_counts['Translation'] == lang].drop(columns=['Translation']).stack().value_counts().head(75).index.tolist()\n",
        "  common_high_sentiment_words[lang] = words_freq\n",
        "\n",
        "common_low_sentiment_words = {}\n",
        "for lang in low_sentiment_word_counts['Translation'].unique():\n",
        "  words_freq = low_sentiment_word_counts[low_sentiment_word_counts['Translation'] == lang].drop(columns=['Translation']).stack().value_counts().head(75).index.tolist()\n",
        "  common_low_sentiment_words[lang] = words_freq\n",
        "\n",
        "# Display results\n",
        "print(\"Common high sentiment words in each language:\")\n",
        "print(common_high_sentiment_words)\n",
        "print(\"Common low Sentiment Words in each language:\")\n",
        "print(common_low_sentiment_words)"
      ],
      "metadata": {
        "id": "9h0RWKAdUk6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating words to English (for comparison)\n",
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Function to translate individual words into English using googletrans library\n",
        "def translate_word_to_english(word, lang):\n",
        "  translator = Translator()\n",
        "  translation = translator.translate(word, src=lang, dest='en')\n",
        "  return translation.text\n",
        "\n",
        "# Create dataframe to add results to\n",
        "translation_df = pd.DataFrame(columns=['Original_Language', 'Original_Words', 'Sentiment', 'English_Translation'])\n",
        "\n",
        "# Translating high sentiment words\n",
        "for lang, words in tqdm(common_high_sentiment_words.items()):\n",
        "  for word in tqdm(words, desc=f\"Translating {lang}\"):\n",
        "    translated_word = translate_word_to_english(word, lang)\n",
        "    translation_df = pd.concat([translation_df, pd.DataFrame({'Original_Language': [lang],\n",
        "                                                              'Original_Words': [word],\n",
        "                                                              'Sentiment': ['High'],\n",
        "                                                              'English_Translation': [translated_word]})])\n",
        "\n",
        "# Translating low sentiment words\n",
        "for lang, words in tqdm(common_low_sentiment_words.items()):\n",
        "  for word in tqdm(words, desc=f\"Translating {lang}\"):\n",
        "    translated_word = translate_word_to_english(word, lang)\n",
        "    translation_df = pd.concat([translation_df, pd.DataFrame({'Original_Language': [lang],\n",
        "                                                              'Original_Words': [word],\n",
        "                                                              'Sentiment': ['Low'],\n",
        "                                                              'English_Translation': [translated_word]})])\n",
        "\n",
        "translation_df.reset_index(drop=True, inplace=True)\n",
        "print(translation_df)\n",
        "\n",
        "# Cleaning the restults\n",
        "translation_df['English_Translation'] = translation_df['English_Translation'].str.replace(r\"[',\\[\\]]\", \"\").str.strip()\n",
        "translation_df['English_Translation'] = translation_df['English_Translation'].str.lower()\n",
        "\n",
        "# Saving off the dataframe\n",
        "translation_df.to_csv('translation_df_all.csv')\n",
        "!cp translation_df_all.csv \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "zOC4hzm3UsAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreating high and low sentiment dataframes with the the newly-translated words\n",
        "\n",
        "df_high_sentiment = pd.DataFrame(columns=['Language', 'High_Sentiment_Words'])\n",
        "df_low_sentiment = pd.DataFrame(columns=['Language', 'Low_Sentiment_Words'])\n",
        "\n",
        "for lang in translation_df['Original_Language'].unique():\n",
        "  lang_df = translation_df[translation_df['Original_Language'] == lang]\n",
        "  unique_high_sentiment_words = set(lang_df[lang_df['Sentiment'] == 'High']['English_Translation'])\n",
        "  unique_low_sentiment_words = set(lang_df[lang_df['Sentiment'] == 'Low']['English_Translation'])\n",
        "\n",
        "  df_high_sentiment = df_high_sentiment.append({'Language': lang, 'High_Sentiment_Words': unique_high_sentiment_words}, ignore_index=True)\n",
        "  df_low_sentiment = df_low_sentiment.append({'Language': lang, 'Low_Sentiment_Words': unique_low_sentiment_words}, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "2EseoWKOVnVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying words unique to each language"
      ],
      "metadata": {
        "id": "S0EuaCvMAup5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate words unique to the sentiment of each language (i.e. for each sentiment,\n",
        "# which words only appear in each language)\n",
        "\n",
        "# Split the dataframes into high and low sentiment\n",
        "high_sentiment_df = translation_df[translation_df['Sentiment'] == 'High']\n",
        "low_sentiment_df = translation_df[translation_df['Sentiment'] == 'Low']\n",
        "\n",
        "# Find unique words per language\n",
        "def find_unique_words(df):\n",
        "  language_words = df.groupby('Original_Language')['English_Translation'].apply(set)\n",
        "  unique_words = {lang: words - set.union(*(language_words[language_words.index != lang])) for lang, words in language_words.items()}\n",
        "  return unique_words\n",
        "\n",
        "# Run function to find unique words for each sentiment\n",
        "unique_high_sentiment_words = find_unique_words(high_sentiment_df)\n",
        "unique_low_sentiment_words = find_unique_words(low_sentiment_df)\n",
        "\n",
        "# Add results to dataframe\n",
        "unique_high_df = pd.DataFrame(list(unique_high_sentiment_words.items()), columns=['Language', 'Unique High Sentiment Words'])\n",
        "unique_low_df = pd.DataFrame(list(unique_low_sentiment_words.items()), columns=['Language', 'Unique Low Sentiment Words'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Unique words for high sentiment verses: \")\n",
        "print(unique_high_df)\n",
        "print(\"Unique words for low sentiment verses: \")\n",
        "print(unique_low_df)"
      ],
      "metadata": {
        "id": "6p8D9ULWV7Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying common words"
      ],
      "metadata": {
        "id": "0dzB9vWqA14v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most common words across languages (by sentiment)\n",
        "from collections import Counter\n",
        "\n",
        "# Create dataframes for high and low sentiment verses\n",
        "high_sentiment_df = translation_df[translation_df['Sentiment'] == 'High']\n",
        "low_sentiment_df = translation_df[translation_df['Sentiment'] == 'Low']\n",
        "\n",
        "# Count frequencies for each word\n",
        "high_word_counts = Counter(high_sentiment_df['English_Translation'].str.split().explode())\n",
        "low_word_counts = Counter(low_sentiment_df['English_Translation'].str.split().explode())\n",
        "\n",
        "# Create dictionaries to store words and their frequencies\n",
        "high_dict = {}\n",
        "low_dict = {}\n",
        "\n",
        "# Only add words that are unique to high and low sentiments\n",
        "for key in high_word_counts.keys():\n",
        "  if key in low_word_counts.keys():\n",
        "    pass\n",
        "  else:\n",
        "    high_dict[key] = high_word_counts.get(key)\n",
        "\n",
        "for key in low_word_counts.keys():\n",
        "  if key in high_word_counts.keys():\n",
        "    pass\n",
        "  else:\n",
        "    low_dict[key] = low_word_counts.get(key)"
      ],
      "metadata": {
        "id": "fMssLeCs2LOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the common high sentiment words\n",
        "sorted_high_word_counts = {k: v for k, v in sorted(high_dict.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "words = list(sorted_high_word_counts.keys())\n",
        "counts = list(sorted_high_word_counts.values())\n",
        "words = [str(word) for word in words]\n",
        "counts = [int(count) for count in counts]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(words[:35], counts[:35])\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top High Sentiment Words')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(words[40:], counts[40:])\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Bottom High Sentiment Words')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fx_eJfp4h3Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the common low sentiment words\n",
        "sorted_low_word_counts = {k: v for k, v in sorted(low_dict.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "words = list(sorted_low_word_counts.keys())\n",
        "counts = list(sorted_low_word_counts.values())\n",
        "words = [str(word) for word in words]\n",
        "counts = [int(count) for count in counts]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(words[:35], counts[:35])\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 35 Low Sentiment Words')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(words[40:], counts[40:])\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Bottom Low Sentiment Words')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eaP0AWmlqdsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying words unique to high or low sentiments in each language"
      ],
      "metadata": {
        "id": "k7lNRmERA5Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the words within each language that are unique to high or low sentiment verses\n",
        "\n",
        "unique_high_sentiment_by_language = {}\n",
        "unique_low_sentiment_by_language = {}\n",
        "\n",
        "for lang in translation_df['Original_Language'].unique():\n",
        "  # Get the high and low sentiment words for the language\n",
        "  lang_high_sentiment_words = set(translation_df[(translation_df['Original_Language'] == lang) & (translation_df['Sentiment'] == 'High')]['English_Translation'])\n",
        "  lang_low_sentiment_words = set(translation_df[(translation_df['Original_Language'] == lang) & (translation_df['Sentiment'] == 'Low')]['English_Translation'])\n",
        "\n",
        "  # Filter out high sentiment words not present in low sentiment verses\n",
        "  unique_high_sentiment_by_language[lang] = lang_high_sentiment_words - lang_low_sentiment_words\n",
        "\n",
        "  # Filter out low sentiment words not present in high sentiment verses\n",
        "  unique_low_sentiment_by_language[lang] = lang_low_sentiment_words - lang_high_sentiment_words\n",
        "\n",
        "print(unique_high_sentiment_by_language)\n",
        "print(unique_low_sentiment_by_language)"
      ],
      "metadata": {
        "id": "2szzrWhg2TxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}